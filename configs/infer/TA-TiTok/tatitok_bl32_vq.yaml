experiment:
    tokenizer_checkpoint: "tatitok_bl32_vq.bin"
    output_dir: "tatitok_bl32_vq"

model:
    vq_model:
        quantize_mode: vq
        codebook_size: 8192
        token_size: 64
        use_l2_norm: False
        commitment_cost: 0.25
        clustering_vq: True
        # vit arch
        vit_enc_model_size: "base"
        vit_dec_model_size: "large"
        vit_enc_patch_size: 16
        vit_dec_patch_size: 16
        num_latent_tokens: 32
        finetune_decoder: False
        is_legacy: False

dataset:
    preprocessing:
        crop_size: 256